{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "01876f68",
   "metadata": {},
   "source": [
    "# AI Powered HR Assistant for Nestle Policy "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0261f38",
   "metadata": {},
   "source": [
    "### 1. Import Important Packages "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ef705a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_chroma import Chroma\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "from langchain.chains import RetrievalQA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57612f43",
   "metadata": {},
   "source": [
    "### 2. Setup OpenAI API calling Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "b0896697",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI API key loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "# Setup open api Key\n",
    "# Load environment variables from .env file if present\n",
    "load_dotenv()\n",
    "\n",
    "# Get the OpenAI API key from environment variable\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "print(\"OpenAI API key loaded successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee291ca5",
   "metadata": {},
   "source": [
    "### 3. Load and process Nestle Policy data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "6461259c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 8 documents from the PDF.\n",
      "First page preview: Policy\n",
      "Mandatory\n",
      "September  2012\n",
      "The Nestlé  \n",
      "Human Resources Policy...\n"
     ]
    }
   ],
   "source": [
    "pdf_path = './Dataset/the_nestle_hr_policy_pdf_2012.pdf'\n",
    "loader = PyPDFLoader(pdf_path)\n",
    "documents = loader.load()\n",
    "\n",
    "print(f\"Loaded {len(documents)} documents from the PDF.\")\n",
    "print(f\"First page preview: {documents[0].page_content[:2000]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f048bfd",
   "metadata": {},
   "source": [
    "### 4. Vector Store initialization and Embeddings generation --"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "64cf6b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Intialize OpenAI Embeddings\n",
    "embeddings = OpenAIEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "bdf11a77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create or load the Chroma vector store using Chroma\n",
    "vector_store = Chroma.from_documents(\n",
    "    documents, \n",
    "    embeddings, \n",
    "    persist_directory=\"./chroma_db\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "b2a903da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector store created and embeddings generated.\n",
      "Number of documents in vector store: 32\n"
     ]
    }
   ],
   "source": [
    "print(\"Vector store created and embeddings generated.\")\n",
    "print(f\"Number of documents in vector store: {vector_store._collection.count()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcfc28dd",
   "metadata": {},
   "source": [
    "### 5. Intialize LLM from OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29a855ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize ChatOpenAI model\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0, max_tokens=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "57dab9dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "llm ChatOpenAI model loaded\n"
     ]
    }
   ],
   "source": [
    "print(\"llm ChatOpenAI model loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "4c3dc511",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a retrieval-based QA chain\n",
    "retriever = vector_store.as_retriever(search_type=\"similarity\", search_kwargs={\"k\":3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "d3b1af76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieval-based QA chain created successfully.\n",
      "Retriever configured to return top 3 similar documents.\n",
      "Retriever search type: similarity\n",
      "Retriever details: tags=['Chroma', 'OpenAIEmbeddings'] vectorstore=<langchain_chroma.vectorstores.Chroma object at 0x7d0458ec28a0> search_kwargs={'k': 3}\n",
      "Vector store details: <langchain_chroma.vectorstores.Chroma object at 0x7d0458ec28a0>\n",
      "Retriever : <bound method BaseRetriever.get_relevant_documents of VectorStoreRetriever(tags=['Chroma', 'OpenAIEmbeddings'], vectorstore=<langchain_chroma.vectorstores.Chroma object at 0x7d0458ec28a0>, search_kwargs={'k': 3})>\n"
     ]
    }
   ],
   "source": [
    "print(\"Retrieval-based QA chain created successfully.\")\n",
    "print(f\"Retriever configured to return top {retriever.search_kwargs['k']} similar documents.\")\n",
    "print(f\"Retriever search type: {retriever.search_type}\")\n",
    "print(f\"Retriever details: {retriever}\")\n",
    "print(f\"Vector store details: {vector_store}\")\n",
    "print(f\"Retriever : {retriever.get_relevant_documents}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dffe6d6",
   "metadata": {},
   "source": [
    "### 6. Create PROMPT Template for Custom Prompt for Chat Assistant Model for NESTLE ~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "ed849a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"\n",
    "\n",
    "Your are Helpful AI assistant for NESTLE HR policies. Your role is to help Employee to provide them accurate information in human understandable format. \n",
    "If you can not find the answer from the provided context, simply state that \"I don't have that information\". Do not make up an answer.\n",
    "\n",
    "Use the following context to answer the question - \n",
    "Context = {context}\n",
    "\n",
    "Question = {question}\n",
    "\n",
    "HR Assistant Reponse:\n",
    "\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "67b04acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMPT = PromptTemplate(\n",
    "    template=template, \n",
    "    input_variables=[\"context\", \"question\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "b62e46d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Retrieval QA Chain\n",
    "\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm, \n",
    "    chain_type=\"stuff\", \n",
    "    retriever=retriever, \n",
    "    chain_type_kwargs={\"prompt\": PROMPT},\n",
    "    return_source_documents=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df6dc212",
   "metadata": {},
   "source": [
    "### 7. Verify & Test HR Assistant Response ~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "6ecace65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test HR Assistant ~\n",
      "\n",
      "Answer:\n"
     ]
    }
   ],
   "source": [
    "print(\"Test HR Assistant ~\")\n",
    "answer = qa_chain({\"query\": \"What is Nestlé's policy on employee training and development?\"})\n",
    "print(\"\\nAnswer:\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
